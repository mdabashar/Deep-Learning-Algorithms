{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16218ccf",
   "metadata": {},
   "source": [
    "# HuggingFace Question Answer System\n",
    "\n",
    "Question answering tasks return an answer given a question. There are two common forms of question answering:\n",
    "\n",
    "1. Extractive: extract the answer from the given context.\n",
    "2. Abstractive: generate an answer from the context that correctly answers the question.\n",
    "\n",
    "This guide will show you how to fine-tune DistilBERT on the SQuAD dataset for extractive question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20282ad9",
   "metadata": {},
   "source": [
    "### Load SQuAD dataset\n",
    "\n",
    "Train: 87599 instances\n",
    "\n",
    "Test: 10570"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aa2a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f6f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# squad_train = load_dataset(\"squad\", split='train')\n",
    "# squad_valid = load_dataset(\"squad\", split='validation')\n",
    "squad_train = load_dataset(\"squad\", split=\"train[:2%]\")\n",
    "squad_valid = load_dataset(\"squad\", split=\"validation[:2%]\")\n",
    "squad = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96fe0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 1752\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 211\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad['train'] = squad_train\n",
    "squad['validation'] = squad_valid\n",
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d00d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(squad_train), len(squad_valid), len(squad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42071f",
   "metadata": {},
   "source": [
    "### Load the DistilBERT tokenizer to process the question and context fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2585a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591c2f2b",
   "metadata": {},
   "source": [
    "There are a few preprocessing steps particular to question answering that you should be aware of:\n",
    "\n",
    "1. Some examples in a dataset may have a very long context that exceeds the maximum input length of the model. Truncate only the context by setting truncation=\"only_second\".\n",
    "2. Next, map the start and end positions of the answer to the original context by setting return_offset_mapping=True.\n",
    "3. With the mapping in hand, you can find the start and end tokens of the answer. Use the sequence_ids method to find which part of the offset corresponds to the question and which corresponds to the context.\n",
    "\n",
    "Here is how you can create a function to truncate and map the start and end tokens of the answer to the context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c5d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "\n",
    "        questions,\n",
    "\n",
    "        examples[\"context\"],\n",
    "\n",
    "        max_length=384,\n",
    "\n",
    "        truncation=\"only_second\",\n",
    "\n",
    "        return_offsets_mapping=True,\n",
    "\n",
    "        padding=\"max_length\",\n",
    "\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "\n",
    "    answers = examples[\"answers\"]\n",
    "\n",
    "    start_positions = []\n",
    "\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "\n",
    "        answer = answers[i]\n",
    "\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "\n",
    "        idx = 0\n",
    "\n",
    "        while sequence_ids[idx] != 1:\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "        context_start = idx\n",
    "\n",
    "        while sequence_ids[idx] == 1:\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "\n",
    "            start_positions.append(0)\n",
    "\n",
    "            end_positions.append(0)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Otherwise it's the start and end token positions\n",
    "\n",
    "            idx = context_start\n",
    "\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "\n",
    "                idx += 1\n",
    "\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "\n",
    "                idx -= 1\n",
    "\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8303b3c2",
   "metadata": {},
   "source": [
    "Use ðŸ¤— Datasets map function to apply the preprocessing function over the entire dataset. You can speed up the map function by setting batched=True to process multiple elements of the dataset at once. Remove the columns you donâ€™t need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61320efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53adbfcec683430a8788ce230f0ab3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1752 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99a01bb342b4229860f831067d014d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/211 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b001d433",
   "metadata": {},
   "source": [
    "Use DefaultDataCollator to create a batch of examples. Unlike other data collators in ðŸ¤— Transformers, the DefaultDataCollator does not apply additional preprocessing such as padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75ee7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52797c0",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "Load DistilBERT with AutoModelForQuestionAnswering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c0ca50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a419e",
   "metadata": {},
   "source": [
    "At this point, only three steps remain:\n",
    "\n",
    "1. Define your training hyperparameters in TrainingArguments.\n",
    "2. Pass the training arguments to Trainer along with the model, dataset, tokenizer, and data collator.\n",
    "3. Call train() to fine-tune your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e800fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "    output_dir=\"./results\",\n",
    "\n",
    "    evaluation_strategy=\"epoch\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "\n",
    "    per_device_eval_batch_size=16,\n",
    "\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    weight_decay=0.01,\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "\n",
    "    model=model,\n",
    "\n",
    "    args=training_args,\n",
    "\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "\n",
    "    eval_dataset=tokenized_squad[\"validation\"],\n",
    "\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    data_collator=data_collator,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c9adb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 1:22:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.178071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.020923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.874038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=330, training_loss=3.4778793797348486, metrics={'train_runtime': 4949.642, 'train_samples_per_second': 1.062, 'train_steps_per_second': 0.067, 'total_flos': 515034520326144.0, 'train_loss': 3.4778793797348486, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea31c50",
   "metadata": {},
   "source": [
    "### Build evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b57f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    pred_start = []\n",
    "    pred_end = []\n",
    "    true_start = []\n",
    "    true_end = []\n",
    "    id_lists = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            pred_start.extend([int(torch.argmax(loc)) for loc in outputs['start_logits']])\n",
    "            pred_end.extend([int(torch.argmax(loc)) for loc in outputs['end_logits']])\n",
    "            true_start.extend(batch['start_positions'].tolist())\n",
    "            true_end.extend(batch['end_positions'].tolist())\n",
    "            id_lists.extend(batch['input_ids'].tolist())\n",
    "            \n",
    "    return true_start, true_end, pred_start, pred_end, id_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4704867",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = tokenized_squad[\"validation\"]\n",
    "valid_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'start_positions', 'end_positions'])\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "true_start, true_end, pred_start, pred_end, id_lists = evaluate(model, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc67009b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57,\n",
       " 57,\n",
       " 161,\n",
       " 161,\n",
       " 167,\n",
       " 162,\n",
       " 72,\n",
       " 160,\n",
       " 162,\n",
       " 159,\n",
       " 73,\n",
       " 159,\n",
       " 74,\n",
       " 163,\n",
       " 170,\n",
       " 46,\n",
       " 62,\n",
       " 163,\n",
       " 80,\n",
       " 163,\n",
       " 77,\n",
       " 71,\n",
       " 42,\n",
       " 53,\n",
       " 159,\n",
       " 46,\n",
       " 160,\n",
       " 71,\n",
       " 162,\n",
       " 162,\n",
       " 27,\n",
       " 133,\n",
       " 66,\n",
       " 40,\n",
       " 29,\n",
       " 44,\n",
       " 27,\n",
       " 25,\n",
       " 29,\n",
       " 26,\n",
       " 35,\n",
       " 33,\n",
       " 37,\n",
       " 29,\n",
       " 95,\n",
       " 25,\n",
       " 43,\n",
       " 29,\n",
       " 26,\n",
       " 29,\n",
       " 44,\n",
       " 46,\n",
       " 24,\n",
       " 44,\n",
       " 25,\n",
       " 67,\n",
       " 47,\n",
       " 45,\n",
       " 59,\n",
       " 72,\n",
       " 43,\n",
       " 36,\n",
       " 66,\n",
       " 43,\n",
       " 43,\n",
       " 73,\n",
       " 70,\n",
       " 75,\n",
       " 50,\n",
       " 68,\n",
       " 70,\n",
       " 40,\n",
       " 47,\n",
       " 44,\n",
       " 45,\n",
       " 41,\n",
       " 38,\n",
       " 47,\n",
       " 45,\n",
       " 74,\n",
       " 33,\n",
       " 34,\n",
       " 55,\n",
       " 33,\n",
       " 30,\n",
       " 15,\n",
       " 31,\n",
       " 30,\n",
       " 30,\n",
       " 32,\n",
       " 29,\n",
       " 36,\n",
       " 35,\n",
       " 21,\n",
       " 26,\n",
       " 31,\n",
       " 30,\n",
       " 34,\n",
       " 27,\n",
       " 29,\n",
       " 30,\n",
       " 28,\n",
       " 29,\n",
       " 28,\n",
       " 33,\n",
       " 31,\n",
       " 17,\n",
       " 29,\n",
       " 26,\n",
       " 18,\n",
       " 20,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 23,\n",
       " 27,\n",
       " 36,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 24,\n",
       " 47,\n",
       " 57,\n",
       " 29,\n",
       " 54,\n",
       " 48,\n",
       " 25,\n",
       " 6,\n",
       " 49,\n",
       " 18,\n",
       " 49,\n",
       " 46,\n",
       " 47,\n",
       " 23,\n",
       " 28,\n",
       " 83,\n",
       " 84,\n",
       " 84,\n",
       " 81,\n",
       " 27,\n",
       " 22,\n",
       " 79,\n",
       " 38,\n",
       " 85,\n",
       " 37,\n",
       " 84,\n",
       " 38,\n",
       " 48,\n",
       " 83,\n",
       " 79,\n",
       " 20,\n",
       " 34,\n",
       " 80,\n",
       " 80,\n",
       " 46,\n",
       " 37,\n",
       " 32,\n",
       " 30,\n",
       " 18,\n",
       " 31,\n",
       " 15,\n",
       " 17,\n",
       " 18,\n",
       " 37,\n",
       " 15,\n",
       " 19,\n",
       " 47,\n",
       " 38,\n",
       " 24,\n",
       " 14,\n",
       " 36,\n",
       " 44,\n",
       " 31,\n",
       " 21,\n",
       " 15,\n",
       " 44,\n",
       " 15,\n",
       " 33,\n",
       " 146,\n",
       " 81,\n",
       " 71,\n",
       " 81,\n",
       " 79,\n",
       " 83,\n",
       " 91,\n",
       " 85,\n",
       " 71,\n",
       " 72,\n",
       " 65,\n",
       " 75,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 149,\n",
       " 17,\n",
       " 23,\n",
       " 60,\n",
       " 23,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 22,\n",
       " 21,\n",
       " 21,\n",
       " 22,\n",
       " 24,\n",
       " 17,\n",
       " 18]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d65fa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] what day was the super bowl played on ? [SEP] super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season . the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 â€“ 10 to earn their third super bowl title . the game was played on february 7 , 2016 , at levi ' s stadium in the san francisco bay area at santa clara , california . as this was the 50th super bowl , the league emphasized the \" golden anniversary \" with various gold - themed initiatives , as well as temporarily suspend ##ing the tradition of naming each super bowl game with roman nu ##meral ##s ( under which the game would have been known as \" super bowl l \" ) , so that the logo could prominently feature the arabic nu ##meral ##s 50 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "february 7 , 2016\n",
      "\n",
      "february 7 , 2016\n",
      "---------10,73,76------------\n"
     ]
    }
   ],
   "source": [
    "def get_ans(tokens, start, end):\n",
    "    answer = tokens[start]\n",
    "    for i in range(start+1, end+1):\n",
    "        if tokens[i][0:2] == \"##\":\n",
    "            answer += tokens[i][2:]\n",
    "        else:\n",
    "            answer += \" \" + tokens[i]\n",
    "    return answer\n",
    "\n",
    "for i in range(10,len(id_lists)):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(id_lists[i])\n",
    "    question = ' '.join(tokens[tokens.index('[CLS]')+1: tokens.index('[SEP]')])\n",
    "    true_ans = get_ans(tokens, true_start[i], true_end[i])\n",
    "    pred_ans = get_ans(tokens, pred_start[i], pred_end[i])\n",
    "    print(' '.join(tokens))\n",
    "    print()\n",
    "    print(true_ans)\n",
    "    print()\n",
    "    print(pred_ans)\n",
    "    print('---------{},{},{}------------'.format(i, pred_start[i], pred_end[i]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfc1338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(pred_tokens, true_tokens):\n",
    "    '''\n",
    "    A straightforward way to check the equality of the two lists in Python \n",
    "    is by using the equality == operator. \n",
    "    When the equality == is used on the list type in Python, \n",
    "    it returns True if the lists are equal and False if they are not.\n",
    "    '''\n",
    "    return int(pred_tokens==true_tokens)\n",
    "\n",
    "def half_exact_match(pred_tokens, true_tokens):\n",
    "    '''\n",
    "    A straightforward way to check the equality of the two lists in Python \n",
    "    is by using the equality == operator. \n",
    "    When the equality == is used on the list type in Python, \n",
    "    it returns True if the lists are equal and False if they are not.\n",
    "    '''\n",
    "    if len(pred_tokens)<=1 or len(true_tokens)<=1:\n",
    "        return int(pred_tokens==true_tokens) \n",
    "    else:\n",
    "        return int(pred_tokens[0]==true_tokens[0] or pred_tokens[-1]==true_tokens[-1])\n",
    "    \n",
    "def any_token_match(pred_tokens, true_tokens):\n",
    "    common_tokens = set(pred_tokens) & set(true_tokens)\n",
    "    return int(len(common_tokens)>0)\n",
    "    \n",
    "\n",
    "def get_prec_rec_f1(pred_tokens, true_tokens):\n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(true_tokens) == 0:\n",
    "        prec = rec = f1 = 1\n",
    "        return prec, rec, f1\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(true_tokens)\n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        prec = rec = f1 = 0\n",
    "        return prec, rec, f1\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(true_tokens)\n",
    "    f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    \n",
    "    return prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84b98dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========2024-01-18 14:46:19.404248========\n",
      "=========2024-01-18 14:46:19.404248========\n",
      "epoch: 3\n",
      "exact_match: 0.13744075829383887\n",
      "half_exact_match: 0.24170616113744076\n",
      "any_match: 0.3080568720379147\n",
      "recall: 0.6562401263823063\n",
      "precision: 0.5191035950054195\n",
      "f1: 0.5308140500545643\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match = 0\n",
    "half_match = 0\n",
    "any_match = 0\n",
    "prec = 0\n",
    "rec = 0\n",
    "f1 = 0\n",
    "count = 0\n",
    "for idx in range(len(pred_start)):\n",
    "\n",
    "    pred_tokens = [i for i in range(pred_start[idx], pred_end[idx]+1)]\n",
    "    true_tokens = [i for i in range(true_start[idx], true_end[idx]+1)]\n",
    "    \n",
    "    match +=  exact_match(pred_tokens, true_tokens)\n",
    "    half_match += half_exact_match(pred_tokens, true_tokens)\n",
    "    any_match += any_token_match(pred_tokens, true_tokens)\n",
    "    \n",
    "    score =  get_prec_rec_f1(pred_tokens, true_tokens)\n",
    "    prec += score[0]\n",
    "    rec += score[1]\n",
    "    f1 += score[2]\n",
    "    count += 1\n",
    "\n",
    "    \n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "string = ''\n",
    "string += '========={}========\\n'.format(now)\n",
    "string += '========={}========\\n'.format(now)\n",
    "string += 'epoch: '+str(training_args.num_train_epochs)+'\\n'\n",
    "string += 'exact_match: '+str(match/count)+'\\n'\n",
    "string += 'half_exact_match: '+str(half_match/count)+'\\n'\n",
    "string += 'any_match: '+str(any_match/count)+'\\n'\n",
    "string += 'recall: '+str(rec/count)+'\\n'\n",
    "string += 'precision: '+str(prec/count)+'\\n'\n",
    "string += 'f1: '+str(f1/count)+'\\n\\n'\n",
    "print(string)\n",
    "\n",
    "with open('Report_BERT_QAM_Squad.txt', 'a+') as FO:\n",
    "    FO.write(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76856049",
   "metadata": {},
   "source": [
    "Reference: https://huggingface.co/docs/transformers/tasks/question_answering#train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
