{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7fc7f33-94fe-4ab8-94ff-27347c335568",
   "metadata": {},
   "source": [
    "# Fine-Tuning a T5 Model on the SQuAD Dataset for Generative Question Answering\n",
    "\n",
    "This code that demonstrates the development of a Question Answering (Q&A) system using the T5 model fine-tuned on the SQuAD dataset. The system is trained on the first N examples from the training set, with validation and testing conducted on separate M-example splits. The process begins by loading and preprocessing the SQuAD data, including tokenizing the questions and context pairs and aligning the answers for model training. The t5-small model is then fine-tuned using the Hugging Face Trainer API with a custom training loop that includes validation and loss reporting. After training, the model is evaluated on a test set using the ROUGE metric to measure the quality of its generated answers. Two types of inputs are tested: one where both the question and context are provided, and another with only the question. The code also computes ROUGE scores for both input types, allowing for analysis of the model's performance based on the presence of context. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc501e-66e7-4dd8-9ede-7dd516c57230",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "debe47fc-6d7a-4fcb-b07f-7435895e88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c25606-856c-4e9b-bbb3-86d0abdd798b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1adefb50670>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f9a46e-5f00-41af-9148-a6eefb6d08ed",
   "metadata": {},
   "source": [
    "# 1. Load and preprocess SQuAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0437040-ad9b-4cfe-9801-d1a801a7102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and preprocess SQuAD dataset\n",
    "dataset = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42bd720f-173b-47ea-9c85-abe55b0ae8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take subsets to avoid overload\n",
    "train_dataset = dataset[\"train\"].select(range(10))\n",
    "val_dataset = dataset[\"validation\"].select(range(10))\n",
    "test_dataset = dataset[\"validation\"].select(range(10))  # No official SQuAD test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f0f0e1d-988a-4ddd-ba32-ced7e6d1dcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e2652a-32ac-4754-8bb5-3a8260021062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(example):\n",
    "    input_text = f\"question: {example['question']}  context: {example['context']}\"\n",
    "    target_text = example[\"answers\"][\"text\"][0]\n",
    "    input_enc = tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    target_enc = tokenizer(target_text, padding=\"max_length\", truncation=True, max_length=32)\n",
    "    input_enc[\"labels\"] = target_enc[\"input_ids\"]\n",
    "    return input_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88504d94-9c04-4af6-965e-742418624148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the datasets\n",
    "train_enc = train_dataset.map(preprocess, batched=False)\n",
    "val_enc = val_dataset.map(preprocess, batched=False)\n",
    "test_enc = test_dataset.map(preprocess, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02b28594-70eb-4a00-8fda-9fba6fa4de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set format\n",
    "columns = ['input_ids', 'attention_mask', 'labels']\n",
    "train_enc.set_format(type=\"torch\", columns=columns)\n",
    "val_enc.set_format(type=\"torch\", columns=columns)\n",
    "test_enc.set_format(type=\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18597be0-05ae-482b-bd88-e52195e9b8cf",
   "metadata": {},
   "source": [
    "# 2. Fine-tune T5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f94948be-a4ba-453f-badb-dd710ecfa989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basharm\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\basharm\\AppData\\Local\\Temp\\ipykernel_37512\\1913569830.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "C:\\Users\\basharm\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\data\\data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>16.777882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>12.778071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.265055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=11.959903717041016, metrics={'train_runtime': 17.0941, 'train_samples_per_second': 1.755, 'train_steps_per_second': 0.351, 'total_flos': 4060254044160.0, 'train_loss': 11.959903717041016, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Fine-tune T5 model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5_squad\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_enc,\n",
    "    eval_dataset=val_enc,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cc463ee-c68e-4d2d-9cc9-b010b4299a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 11.265054702758789\n"
     ]
    }
   ],
   "source": [
    "# Report training and validation losses\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Validation Loss:\", metrics[\"eval_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab92d270-fb05-40b6-99ca-21142f07e1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./t5_squad_model\\\\tokenizer_config.json',\n",
       " './t5_squad_model\\\\special_tokens_map.json',\n",
       " './t5_squad_model\\\\spiece.model',\n",
       " './t5_squad_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "model.save_pretrained(\"./t5_squad_model\")\n",
    "tokenizer.save_pretrained(\"./t5_squad_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08673b27-6a94-4ff7-aa20-d438509249e5",
   "metadata": {},
   "source": [
    "# 3. Evaluate on test set using ROUGE (updated slicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a57cf63-8158-4bc2-9f24-a53f5e95181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Evaluate on test set using ROUGE (updated slicing)\n",
    "def generate_answers(dataset, use_context=True, limit=100):\n",
    "    # Make sure we have a row-oriented Dataset\n",
    "    subset = dataset.select(range(limit))\n",
    "    inputs = []\n",
    "    for ex in subset:\n",
    "        if use_context:\n",
    "            inputs.append(f\"question: {ex['question']}  context: {ex['context']}\")\n",
    "        else:\n",
    "            inputs.append(f\"question: {ex['question']}\")\n",
    "    tokenized = tokenizer(\n",
    "        inputs,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    outputs = model.generate(**tokenized)\n",
    "    answers = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    references = [ex[\"answers\"][\"text\"][0] for ex in subset]\n",
    "    return answers, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c47d064-31cb-4755-9991-8f63dc0fc651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now call it:\n",
    "answers_ctx, refs_ctx = generate_answers(test_dataset, use_context=True,  limit=10)\n",
    "answers_noctx, refs_noctx = generate_answers(test_dataset, use_context=False, limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19328226-90b1-4192-8572-60d87ea30d55",
   "metadata": {},
   "source": [
    "# 4. Evaluate on test set using ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "617def66-d9cf-4dc3-a260-e71bb8a163eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUGE with context: {'rouge1': {'precision': 0.7}, 'rouge2': {'precision': 0.6}, 'rougeL': {'precision': 0.7}}\n",
      "\n",
      "ROUGE without context: {'rouge1': {'precision': 0.0}, 'rouge2': {'precision': 0.0}, 'rougeL': {'precision': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluate on test set using ROUGE\n",
    "def compute_rouge(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    results = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        score = scorer.score(ref, pred)\n",
    "        for k in results:\n",
    "            results[k].append(score[k].fmeasure)\n",
    "    return {k: {\"precision\": sum(results[k])/len(results[k])} for k in results}\n",
    "\n",
    "rouge_with_ctx = compute_rouge(answers_ctx, refs_ctx)\n",
    "rouge_no_ctx   = compute_rouge(answers_noctx, refs_noctx)\n",
    "\n",
    "print(\"\\nROUGE with context:\", rouge_with_ctx)\n",
    "print(\"\\nROUGE without context:\", rouge_no_ctx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
