{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f92193",
   "metadata": {},
   "source": [
    "### Reference: \n",
    "\n",
    "https://huggingface.co/MaRiOrOsSi/t5-base-finetuned-question-answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f40dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  transformers  import  AutoTokenizer, AutoModelWithLMHead, pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea343f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MaRiOrOsSi/t5-base-finetuned-question-answering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c83f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ccb1e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basharm\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1132: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813da14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Bashar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basharm\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "question = \"Who graduated from QUT?\"\n",
    "context = \"The name of the scientist is Dr. Bashar. He graduated from QUT.\"\n",
    "input = f\"question: {question} context: {context}\"\n",
    "encoded_input = tokenizer([input],\n",
    "                             return_tensors='pt',\n",
    "                             max_length=512,\n",
    "                             truncation=True)\n",
    "output = model.generate(input_ids = encoded_input.input_ids,\n",
    "                            attention_mask = encoded_input.attention_mask)\n",
    "output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fdf127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/basharm/.cache/huggingface/datasets/parquet/plain_text-d0ce9b3222e19e32/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaaedb46bb5c43b9b1cc3473d491918d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "squad = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d8c81de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 10570\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ff9ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basharm\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Respon Count 100\n",
      "Completed Respon Count 200\n",
      "Completed Respon Count 300\n",
      "Completed Respon Count 400\n",
      "Completed Respon Count 500\n",
      "Completed Respon Count 600\n",
      "Completed Respon Count 700\n",
      "Completed Respon Count 800\n",
      "Completed Respon Count 900\n",
      "Completed Respon Count 1000\n",
      "Completed Respon Count 1100\n",
      "Completed Respon Count 1200\n",
      "Completed Respon Count 1300\n",
      "Completed Respon Count 1400\n",
      "Completed Respon Count 1500\n",
      "Completed Respon Count 1600\n",
      "Completed Respon Count 1700\n",
      "Completed Respon Count 1800\n",
      "Completed Respon Count 1900\n",
      "Completed Respon Count 2000\n",
      "Completed Respon Count 2100\n",
      "Completed Respon Count 2200\n",
      "Completed Respon Count 2300\n",
      "Completed Respon Count 2400\n",
      "Completed Respon Count 2500\n",
      "Completed Respon Count 2600\n",
      "Completed Respon Count 2700\n",
      "Completed Respon Count 2800\n",
      "Completed Respon Count 2900\n",
      "Completed Respon Count 3000\n",
      "Completed Respon Count 3100\n",
      "Completed Respon Count 3200\n",
      "Completed Respon Count 3300\n",
      "Completed Respon Count 3400\n",
      "Completed Respon Count 3500\n",
      "Completed Respon Count 3600\n",
      "Completed Respon Count 3700\n",
      "Completed Respon Count 3800\n",
      "Completed Respon Count 3900\n",
      "Completed Respon Count 4000\n",
      "Completed Respon Count 4100\n",
      "Completed Respon Count 4200\n",
      "Completed Respon Count 4300\n",
      "Completed Respon Count 4400\n",
      "Completed Respon Count 4500\n",
      "Completed Respon Count 4600\n",
      "Completed Respon Count 4700\n",
      "Completed Respon Count 4800\n",
      "Completed Respon Count 4900\n",
      "Completed Respon Count 5000\n",
      "Completed Respon Count 5100\n",
      "Completed Respon Count 5200\n",
      "Completed Respon Count 5300\n",
      "Completed Respon Count 5400\n",
      "Completed Respon Count 5500\n",
      "Completed Respon Count 5600\n",
      "Completed Respon Count 5700\n",
      "Completed Respon Count 5800\n",
      "Completed Respon Count 5900\n",
      "Completed Respon Count 6000\n",
      "Completed Respon Count 6100\n",
      "Completed Respon Count 6200\n",
      "Completed Respon Count 6300\n",
      "Completed Respon Count 6400\n",
      "Completed Respon Count 6500\n",
      "Completed Respon Count 6600\n",
      "Completed Respon Count 6700\n",
      "Completed Respon Count 6800\n",
      "Completed Respon Count 6900\n",
      "Completed Respon Count 7000\n",
      "Completed Respon Count 7100\n",
      "Completed Respon Count 7200\n",
      "Completed Respon Count 7300\n",
      "Completed Respon Count 7400\n",
      "Completed Respon Count 7500\n",
      "Completed Respon Count 7600\n",
      "Completed Respon Count 7700\n",
      "Completed Respon Count 7800\n",
      "Completed Respon Count 7900\n",
      "Completed Respon Count 8000\n",
      "Completed Respon Count 8100\n",
      "Completed Respon Count 8200\n",
      "Completed Respon Count 8300\n",
      "Completed Respon Count 8400\n",
      "Completed Respon Count 8500\n",
      "Completed Respon Count 8600\n",
      "Completed Respon Count 8700\n",
      "Completed Respon Count 8800\n",
      "Completed Respon Count 8900\n",
      "Completed Respon Count 9000\n",
      "Completed Respon Count 9100\n",
      "Completed Respon Count 9200\n",
      "Completed Respon Count 9300\n",
      "Completed Respon Count 9400\n",
      "Completed Respon Count 9500\n",
      "Completed Respon Count 9600\n",
      "Completed Respon Count 9700\n",
      "Completed Respon Count 9800\n",
      "Completed Respon Count 9900\n",
      "Completed Respon Count 10000\n",
      "Completed Respon Count 10100\n",
      "Completed Respon Count 10200\n",
      "Completed Respon Count 10300\n",
      "Completed Respon Count 10400\n",
      "Completed Respon Count 10500\n"
     ]
    }
   ],
   "source": [
    "def predict_answer(question, context):\n",
    "    input = f\"question: {question} context: {context}\"\n",
    "    encoded_input = tokenizer([input],\n",
    "                             return_tensors='pt',\n",
    "                             max_length=512,\n",
    "                             truncation=True)\n",
    "    output = model.generate(input_ids = encoded_input.input_ids,\n",
    "                            attention_mask = encoded_input.attention_mask)\n",
    "    output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return output\n",
    "\n",
    "count = 0\n",
    "out_rows = []\n",
    "for row in squad['validation']:\n",
    "    question = row['question']\n",
    "    #print(question)\n",
    "    context = row['context']\n",
    "    #print(context)\n",
    "    ans = row['answers']['text'][0]\n",
    "    #print(ans)\n",
    "    pred_ans = predict_answer(question, context)\n",
    "    #print(pred_ans)\n",
    "    out_row = {'answer': ans, 'pred_ans': pred_ans}\n",
    "    out_rows.append(out_row)\n",
    "    count += 1\n",
    "    if count%100==0:\n",
    "        print('Completed Respon Count', count)\n",
    "    \n",
    "df_out_val = pd.DataFrame(out_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0228505c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>pred_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>Denver Broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>Denver Broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>Denver Broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gold</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10565</th>\n",
       "      <td>kilogram-force</td>\n",
       "      <td>Kilowatt-force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10566</th>\n",
       "      <td>kilopond</td>\n",
       "      <td>Kilopond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10567</th>\n",
       "      <td>slug</td>\n",
       "      <td>metric slug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10568</th>\n",
       "      <td>kip</td>\n",
       "      <td>Kilowatt-force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>sthène</td>\n",
       "      <td>Kilowatt force</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10570 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        answer                 pred_ans\n",
       "0               Denver Broncos           Denver Broncos\n",
       "1            Carolina Panthers           Denver Broncos\n",
       "2      Santa Clara, California  Santa Clara, California\n",
       "3               Denver Broncos           Denver Broncos\n",
       "4                         gold                     gold\n",
       "...                        ...                      ...\n",
       "10565           kilogram-force           Kilowatt-force\n",
       "10566                 kilopond                 Kilopond\n",
       "10567                     slug              metric slug\n",
       "10568                      kip           Kilowatt-force\n",
       "10569                   sthène           Kilowatt force\n",
       "\n",
       "[10570 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b406695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_val.to_csv('T5_squad_valid.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e942c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(pred_tokens, true_tokens):\n",
    "    '''\n",
    "    A straightforward way to check the equality of the two lists in Python \n",
    "    is by using the equality == operator. \n",
    "    When the equality == is used on the list type in Python, \n",
    "    it returns True if the lists are equal and False if they are not.\n",
    "    '''\n",
    "    return int(pred_tokens==true_tokens)\n",
    "\n",
    "def half_exact_match(pred_tokens, true_tokens):\n",
    "    '''\n",
    "    A straightforward way to check the equality of the two lists in Python \n",
    "    is by using the equality == operator. \n",
    "    When the equality == is used on the list type in Python, \n",
    "    it returns True if the lists are equal and False if they are not.\n",
    "    '''\n",
    "    if len(pred_tokens)<=1 or len(true_tokens)<=1:\n",
    "        return int(pred_tokens==true_tokens) \n",
    "    else:\n",
    "        return int(pred_tokens[0]==true_tokens[0] or pred_tokens[-1]==true_tokens[-1])\n",
    "    \n",
    "def any_token_match(pred_tokens, true_tokens):\n",
    "    common_tokens = set(pred_tokens) & set(true_tokens)\n",
    "    return int(len(common_tokens)>0)\n",
    "    \n",
    "\n",
    "def get_prec_rec_f1(pred_tokens, true_tokens):\n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(true_tokens) == 0:\n",
    "        prec = rec = f1 = 1\n",
    "        return prec, rec, f1\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(true_tokens)\n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        prec = rec = f1 = 0\n",
    "        return prec, rec, f1\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(true_tokens)\n",
    "    f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    \n",
    "    return prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bf6636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========2025-02-21 14:52:02.533026========\n",
      "=========2025-02-21 14:52:02.533026========\n",
      "exact_match: 0.38420056764427624\n",
      "half_exact_match: 0.584484389782403\n",
      "any_match: 0.7371807000946073\n",
      "recall: 0.6144846712364499\n",
      "precision: 0.6243597824517078\n",
      "f1: 0.6001928249863442\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match = 0\n",
    "half_match = 0\n",
    "any_match = 0\n",
    "prec = 0\n",
    "rec = 0\n",
    "f1 = 0\n",
    "count = 0\n",
    "for idx in df_out_val.index:\n",
    "\n",
    "    pred_tokens = df_out_val.loc[idx, 'pred_ans'].split()\n",
    "    true_tokens = df_out_val.loc[idx, 'answer'].split()\n",
    "    \n",
    "    match +=  exact_match(pred_tokens, true_tokens)\n",
    "    half_match += half_exact_match(pred_tokens, true_tokens)\n",
    "    any_match += any_token_match(pred_tokens, true_tokens)\n",
    "    \n",
    "    score =  get_prec_rec_f1(pred_tokens, true_tokens)\n",
    "    prec += score[0]\n",
    "    rec += score[1]\n",
    "    f1 += score[2]\n",
    "    count += 1\n",
    "\n",
    "    \n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "string = ''\n",
    "string += '========={}========\\n'.format(now)\n",
    "string += '========={}========\\n'.format(now)\n",
    "string += 'exact_match: '+str(match/count)+'\\n'\n",
    "string += 'half_exact_match: '+str(half_match/count)+'\\n'\n",
    "string += 'any_match: '+str(any_match/count)+'\\n'\n",
    "string += 'recall: '+str(rec/count)+'\\n'\n",
    "string += 'precision: '+str(prec/count)+'\\n'\n",
    "string += 'f1: '+str(f1/count)+'\\n\\n'\n",
    "print(string)\n",
    "\n",
    "with open('Report_T5_Squad.txt', 'a+') as FO:\n",
    "    FO.write(string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
